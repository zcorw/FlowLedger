version: "3.9"

name: flow-ledger

services:
  db:
    image: postgres:12-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-flow_ledger}
      POSTGRES_USER: ${POSTGRES_USER:-flow_ledger}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-flow_ledger}
    ports:
      - "${PG_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 10
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - backend

  db-migrate:
    image: postgres:12-alpine
    depends_on:
      db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-flow_ledger}
      POSTGRES_USER: ${POSTGRES_USER:-flow_ledger}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-flow_ledger}
    volumes:
      - ./:/work:ro
    working_dir: /work
    entrypoint: ["/bin/sh","-lc"]
    command: >-
      'set -e;
       echo "Applying SQL schemas (deterministic order)...";
       apply() { echo "==> $$1"; PGPASSWORD=$$POSTGRES_PASSWORD psql -h db -U $$POSTGRES_USER -d $$POSTGRES_DB -v ON_ERROR_STOP=1 -f "$$1"; };
       # Enforce dependency order: extensions -> currency -> user -> deposit -> expense -> loan -> scheduler
       for f in \
         /work/sql/schema/extensions.sql \
         /work/sql/schema/currency.sql \
         /work/sql/schema/user.sql \
         /work/sql/schema/file.sql \
         /work/sql/schema/deposit.sql \
         /work/sql/schema/expense.sql \
         /work/sql/schema/loan.sql \
         /work/sql/schema/scheduler.sql; do \
           [ -f "$$f" ] && apply "$$f" || true; \
       done; \
       # Apply any remaining *.sql not covered above (extensions, views, etc.)
       for f in /work/sql/schema/*.sql; do \
         case "$$f" in \
           */user.sql|*/currency.sql|*/deposit.sql|*/expense.sql|*/loan.sql|*/scheduler.sql) continue;; \
         esac; \
         apply "$$f"; \
       done; \
       if ls /work/sql/sample/*.sql >/dev/null 2>&1; then \
         echo "Applying sample data..."; \
         for f in /work/sql/sample/*.sql; do \
           apply "$$f"; \
         done; \
       else \
         echo "No sample data found (sql/sample)."; \
       fi; \
       if [ -f /work/scripts/run_migration.sql ]; then \
         echo "Applying scripts/run_migration.sql..."; \
         apply /work/scripts/run_migration.sql; \
       fi; \
       echo "Database migration job completed."'
    networks:
      - backend

  api:
    build:
      context: .
      dockerfile: api/Dockerfile
    depends_on:
      db:
        condition: service_healthy
    env_file:
      - ./.env
    environment:
      # Prefer POSTGRES_* as the single source of truth; DATABASE_URL is optional.
      DATABASE_URL: ${DATABASE_URL:-postgresql://${POSTGRES_USER:-flow_ledger}:${POSTGRES_PASSWORD:-flow_ledger}@db:5432/${POSTGRES_DB:-flow_ledger}}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      UPLOAD_DIR: /data/uploads
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - ./api:/app
      - ${API_DATA_DIR:-./data}:/data
    networks:
      - backend
    stop_signal: SIGTERM
    stop_grace_period: 30s
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/v1/healthz')\""]
      interval: 10s
      timeout: 3s
      retries: 5
    cpus: "1.0"
    mem_limit: 512M

  bot:
    build:
      context: .
      dockerfile: bot/Dockerfile
    depends_on:
      api:
        condition: service_started
    env_file:
      - .env
    environment:
      API_BASE_URL: ${API_BASE_URL:-http://api:8000/v1}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      BOT_STATE_PATH: ${BOT_STATE_PATH:-/app/data/bot_state.json}
    ports:
      - "${BOT_PORT:-9080}:7000"
    restart: unless-stopped
    volumes:
      - ./bot:/app
      - botdata:/app/data
    networks:
      - backend

  scheduler:
    build:
      context: .
      dockerfile: api/Dockerfile
    depends_on:
      api:
        condition: service_started
    env_file:
      - .env
    environment:
      API_BASE_URL: ${API_BASE_URL:-http://api:8000/v1}
      FX_CRON_SCHEDULE: ${FX_CRON_SCHEDULE:-0 9 * * *}
      FX_TIMEOUT_SECONDS: ${FX_TIMEOUT_SECONDS:-10}
      FX_SYNC_ON_START: ${FX_SYNC_ON_START:-false}
    command: python -m app.tasks.scheduler_service
    volumes:
      - ./api:/app
    networks:
      - backend

volumes:
  pgdata:
    driver: local
  botdata:
    driver: local

networks:
  backend:
    driver: bridge
